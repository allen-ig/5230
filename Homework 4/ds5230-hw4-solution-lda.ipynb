{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Title Topics using Latents Dirichlet Allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0) Data Cleaning. You can either run the following cell or directly run the script prep.py in terminal with the dataset path and stopwords_english path as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rtitle = re.compile(r'^#\\*\\s*(.+)')\n",
    "# stemmer = SnowballStemmer('english')\n",
    "# titles = []\n",
    "# stopwords = []\n",
    "# parsed_titles = []\n",
    "\n",
    "# with open('stopwords_english.txt') as fsw:\n",
    "#     for word in fsw.readlines():\n",
    "#         word = word.strip('\\n')\n",
    "#         stopwords.append(word)\n",
    "# fsw.close()\n",
    "\n",
    "# with open('publications.txt') as fin:\n",
    "#     for line in fin.readlines():\n",
    "#         line = line.strip('\\n')\n",
    "#         mtitle = rtitle.match(line)\n",
    "#         ## if it is a title string\n",
    "#         if mtitle:\n",
    "#             title = mtitle.group(1).lower()\n",
    "#             titles.append(title[:-1])\n",
    "# fin.close()\n",
    "\n",
    "# fout = open('titles_prep.txt', 'w+')\n",
    "# for i, words in enumerate(titles):\n",
    "#     words = words.split(\" \")\n",
    "#     words = [re.match('[a-zA-Z0-9]+', stemmer.stem(word)).group() for word in words if re.match('[a-zA-Z0-9]+', stemmer.stem(word)) is not None]\n",
    "#     words = ['NUM' if re.match('[0-9]+', word) is not None else word for word in words]\n",
    "#     words = list(filter(None, [\"\" if word in stopwords else word for word in words]))\n",
    "#     words = ' '.join(words)\n",
    "#     fout.write(words + '\\n')\n",
    "#     parsed_titles.append(words)\n",
    "#     if i % 100000 == 0 :\n",
    "#         print(i)\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== raw dataset loaded =====\n",
      "===== stopwords list loaded =====\n",
      "===== start to parse text =====\n",
      "===== 0 titles are parsed successfully =====\n",
      "===== 100000 titles are parsed successfully =====\n",
      "===== 200000 titles are parsed successfully =====\n",
      "===== 300000 titles are parsed successfully =====\n",
      "===== 400000 titles are parsed successfully =====\n",
      "===== 500000 titles are parsed successfully =====\n",
      "===== 600000 titles are parsed successfully =====\n",
      "===== 700000 titles are parsed successfully =====\n",
      "===== parsing completed. parsed data was saved in file preprocessed.txt, please load this as the input for your model. End. =====\n"
     ]
    }
   ],
   "source": [
    "load_and_process_data('publications.txt', 'stopwords_english.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1) Load the preprocessed dataset and convert it to word count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "*** load dataset and convert bag of words represenetations.***\n",
    "\"\"\"\n",
    "prep_words = []\n",
    "with open('preprocessed.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        prep_words.append(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=800)\n",
    "X = vectorizer.fit(prep_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix = X.transform(prep_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2) Now apply LDA to the dataset with different number of topics = 10, 20, 50. In each experimetn, print the top 10 words in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_num = [10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03333698, 0.03334105, 0.03333333, ..., 0.03333333, 0.03333662,\n",
       "        0.03334231],\n",
       "       [0.02      , 0.02      , 0.02000366, ..., 0.02      , 0.22      ,\n",
       "        0.42      ],\n",
       "       [0.02      , 0.02000057, 0.02      , ..., 0.02      , 0.02      ,\n",
       "        0.02      ],\n",
       "       ...,\n",
       "       [0.13291227, 0.011112  , 0.01111361, ..., 0.1222222 , 0.25696928,\n",
       "        0.01111651],\n",
       "       [0.36666667, 0.03333333, 0.03333333, ..., 0.03333333, 0.36666666,\n",
       "        0.03333333],\n",
       "       [0.02000244, 0.02000955, 0.02      , ..., 0.42      , 0.02      ,\n",
       "        0.02      ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "*** LDA ***\n",
    "\"\"\"\n",
    "lda = LatentDirichletAllocation(n_components=10)\n",
    "id_topic = lda.fit_transform(X_matrix)\n",
    "id_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = {}\n",
    "\n",
    "for topic, comp in enumerate(lda.components_):\n",
    "    word_idx = np.argsort(comp)[::-1][:10]\n",
    "    topic_words[topic] = [vocab[i] for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['algorithm',\n",
       "  'imag',\n",
       "  'multi',\n",
       "  'detect',\n",
       "  'framework',\n",
       "  'fuzzi',\n",
       "  'video',\n",
       "  'general',\n",
       "  'logic',\n",
       "  'pattern'],\n",
       " 1: ['use',\n",
       "  'estim',\n",
       "  'manag',\n",
       "  'web',\n",
       "  'system',\n",
       "  'process',\n",
       "  'generat',\n",
       "  'analysi',\n",
       "  'predict',\n",
       "  'servic'],\n",
       " 2: ['method',\n",
       "  'analysi',\n",
       "  'evalu',\n",
       "  'function',\n",
       "  'program',\n",
       "  'recognit',\n",
       "  'select',\n",
       "  'languag',\n",
       "  'filter',\n",
       "  'parallel'],\n",
       " 3: ['comput',\n",
       "  'inform',\n",
       "  'multipl',\n",
       "  'visual',\n",
       "  'system',\n",
       "  'model',\n",
       "  'technolog',\n",
       "  'map',\n",
       "  'environ',\n",
       "  'approxim'],\n",
       " 4: ['network',\n",
       "  'approach',\n",
       "  'applic',\n",
       "  'optim',\n",
       "  'perform',\n",
       "  'distribut',\n",
       "  'high',\n",
       "  'system',\n",
       "  'scheme',\n",
       "  'neural'],\n",
       " 5: ['learn',\n",
       "  'effect',\n",
       "  'interact',\n",
       "  'model',\n",
       "  'adapt',\n",
       "  'user',\n",
       "  'digit',\n",
       "  'semant',\n",
       "  'virtual',\n",
       "  'human'],\n",
       " 6: ['design',\n",
       "  'system',\n",
       "  'dynam',\n",
       "  'simul',\n",
       "  'model',\n",
       "  'architectur',\n",
       "  'two',\n",
       "  'search',\n",
       "  'classif',\n",
       "  'non'],\n",
       " 7: ['problem',\n",
       "  'studi',\n",
       "  'new',\n",
       "  'graph',\n",
       "  'effici',\n",
       "  'implement',\n",
       "  'case',\n",
       "  'set',\n",
       "  'toward',\n",
       "  'optim'],\n",
       " 8: ['base',\n",
       "  'data',\n",
       "  'model',\n",
       "  'time',\n",
       "  'test',\n",
       "  'structur',\n",
       "  'rout',\n",
       "  'oper',\n",
       "  'engin',\n",
       "  'construct'],\n",
       " 9: ['control',\n",
       "  'network',\n",
       "  'wireless',\n",
       "  'mobil',\n",
       "  'code',\n",
       "  'system',\n",
       "  'sensor',\n",
       "  'integr',\n",
       "  'channel',\n",
       "  'secur']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\program files\\python36\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "e:\\program files\\python36\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00666667, 0.00666667, 0.00666667, ..., 0.00666667, 0.00666667,\n",
       "        0.00666667],\n",
       "       [0.004     , 0.004     , 0.004     , ..., 0.004     , 0.004     ,\n",
       "        0.004     ],\n",
       "       [0.004     , 0.004     , 0.004     , ..., 0.004     , 0.004     ,\n",
       "        0.004     ],\n",
       "       ...,\n",
       "       [0.00222222, 0.00222222, 0.11333333, ..., 0.00222222, 0.00222222,\n",
       "        0.00222222],\n",
       "       [0.00666667, 0.00666667, 0.00666667, ..., 0.00666667, 0.00666667,\n",
       "        0.00666667],\n",
       "       [0.004     , 0.004     , 0.004     , ..., 0.004     , 0.004     ,\n",
       "        0.004     ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda20 = LatentDirichletAllocation(n_components=20)\n",
    "lda20.fit_transform(X_matrix)\n",
    "lda50 = LatentDirichletAllocation(n_components=50)\n",
    "lda50.fit_transform(X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\program files\\python36\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "id_topic20 = lda20.fit_transform(X_matrix)\n",
    "\n",
    "topic_words20 = {}\n",
    "\n",
    "for topic, comp in enumerate(lda20.components_):  \n",
    "    word_idx = np.argsort(comp)[::-1][:10]\n",
    "    topic_words20[topic] = [vocab[i] for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['data',\n",
       "  'structur',\n",
       "  'automat',\n",
       "  'mine',\n",
       "  'field',\n",
       "  'impact',\n",
       "  'text',\n",
       "  'devic',\n",
       "  'scalabl',\n",
       "  'medic'],\n",
       " 1: ['comput',\n",
       "  'environ',\n",
       "  'parallel',\n",
       "  'activ',\n",
       "  'collabor',\n",
       "  'statist',\n",
       "  'cooper',\n",
       "  'de',\n",
       "  'grid',\n",
       "  'cloud'],\n",
       " 2: ['process',\n",
       "  'distribut',\n",
       "  'visual',\n",
       "  'map',\n",
       "  'product',\n",
       "  'oper',\n",
       "  'resourc',\n",
       "  'bound',\n",
       "  'energi',\n",
       "  'queri'],\n",
       " 3: ['applic',\n",
       "  'detect',\n",
       "  'recognit',\n",
       "  'fuzzi',\n",
       "  'scheme',\n",
       "  'secur',\n",
       "  'robust',\n",
       "  'social',\n",
       "  'speech',\n",
       "  'signal'],\n",
       " 4: ['algorithm',\n",
       "  'design',\n",
       "  'problem',\n",
       "  'dynam',\n",
       "  'estim',\n",
       "  'function',\n",
       "  'graph',\n",
       "  'linear',\n",
       "  'filter',\n",
       "  'pattern'],\n",
       " 5: ['imag',\n",
       "  'multi',\n",
       "  'improv',\n",
       "  'robot',\n",
       "  'measur',\n",
       "  'video',\n",
       "  'local',\n",
       "  'space',\n",
       "  'segment',\n",
       "  'retriev'],\n",
       " 6: ['adapt',\n",
       "  'perform',\n",
       "  'effici',\n",
       "  'code',\n",
       "  'effect',\n",
       "  'power',\n",
       "  'mobil',\n",
       "  'program',\n",
       "  'interact',\n",
       "  'complex'],\n",
       " 7: ['network',\n",
       "  'studi',\n",
       "  'wireless',\n",
       "  'sensor',\n",
       "  'neural',\n",
       "  'generat',\n",
       "  'implement',\n",
       "  'theori',\n",
       "  'combin',\n",
       "  'vector'],\n",
       " 8: ['servic',\n",
       "  'channel',\n",
       "  'approxim',\n",
       "  'solut',\n",
       "  'transform',\n",
       "  'equat',\n",
       "  'onlin',\n",
       "  'sequenc',\n",
       "  'qualiti',\n",
       "  'autom'],\n",
       " 9: ['web',\n",
       "  'search',\n",
       "  'classif',\n",
       "  'via',\n",
       "  'databas',\n",
       "  'rule',\n",
       "  'feedback',\n",
       "  'evolut',\n",
       "  'chain',\n",
       "  'decomposit'],\n",
       " 10: ['high',\n",
       "  'framework',\n",
       "  'multipl',\n",
       "  'general',\n",
       "  'protocol',\n",
       "  'rout',\n",
       "  'engin',\n",
       "  'rate',\n",
       "  'domain',\n",
       "  'internet'],\n",
       " 11: ['analysi',\n",
       "  'optim',\n",
       "  'simul',\n",
       "  'techniqu',\n",
       "  'cluster',\n",
       "  'languag',\n",
       "  'game',\n",
       "  'intellig',\n",
       "  'larg',\n",
       "  'context'],\n",
       " 12: ['model',\n",
       "  'approach',\n",
       "  'inform',\n",
       "  'knowledg',\n",
       "  'semant',\n",
       "  'relat',\n",
       "  'sens',\n",
       "  'joint',\n",
       "  'formal',\n",
       "  'connect'],\n",
       " 13: ['object',\n",
       "  'test',\n",
       "  'two',\n",
       "  'motion',\n",
       "  'experi',\n",
       "  'class',\n",
       "  'design',\n",
       "  'interfac',\n",
       "  'traffic',\n",
       "  'compress'],\n",
       " 14: ['system',\n",
       "  'control',\n",
       "  'evalu',\n",
       "  'architectur',\n",
       "  'communic',\n",
       "  'hybrid',\n",
       "  'embed',\n",
       "  'memori',\n",
       "  'reliabl',\n",
       "  'issu'],\n",
       " 15: ['learn',\n",
       "  'manag',\n",
       "  'human',\n",
       "  'self',\n",
       "  'strategi',\n",
       "  'track',\n",
       "  'project',\n",
       "  'comparison',\n",
       "  'alloc',\n",
       "  'practic'],\n",
       " 16: ['base',\n",
       "  'time',\n",
       "  'technolog',\n",
       "  'low',\n",
       "  'nonlinear',\n",
       "  'flow',\n",
       "  'represent',\n",
       "  'fault',\n",
       "  'paramet',\n",
       "  'compar'],\n",
       " 17: ['use',\n",
       "  'softwar',\n",
       "  'develop',\n",
       "  'predict',\n",
       "  'case',\n",
       "  'featur',\n",
       "  'user',\n",
       "  'intern',\n",
       "  'tool',\n",
       "  'plan'],\n",
       " 18: ['method',\n",
       "  'new',\n",
       "  'select',\n",
       "  'set',\n",
       "  'toward',\n",
       "  'schedul',\n",
       "  'research',\n",
       "  'machin',\n",
       "  'access',\n",
       "  'novel'],\n",
       " 19: ['system',\n",
       "  'integr',\n",
       "  'support',\n",
       "  'real',\n",
       "  'logic',\n",
       "  'non',\n",
       "  'decis',\n",
       "  'constraint',\n",
       "  'group',\n",
       "  'mimo']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\program files\\python36\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "id_topic50 = lda50.fit_transform(X_matrix)\n",
    "\n",
    "topic_words50 = {}\n",
    "\n",
    "for topic, comp in enumerate(lda50.components_): \n",
    "    word_idx = np.argsort(comp)[::-1][:10]\n",
    "    topic_words50[topic] = [vocab[i] for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['time',\n",
       "  'linear',\n",
       "  'nonlinear',\n",
       "  'ad',\n",
       "  'radio',\n",
       "  'hoc',\n",
       "  'industri',\n",
       "  'packet',\n",
       "  'regress',\n",
       "  'receiv'],\n",
       " 1: ['data',\n",
       "  'structur',\n",
       "  'complex',\n",
       "  'automat',\n",
       "  'mine',\n",
       "  'text',\n",
       "  'stream',\n",
       "  'medic',\n",
       "  'market',\n",
       "  'media'],\n",
       " 2: ['develop',\n",
       "  'strategi',\n",
       "  'resourc',\n",
       "  'project',\n",
       "  'chang',\n",
       "  'valu',\n",
       "  'educ',\n",
       "  'valid',\n",
       "  'china',\n",
       "  'motor'],\n",
       " 3: ['distribut',\n",
       "  'robust',\n",
       "  'non',\n",
       "  'product',\n",
       "  'stochast',\n",
       "  'memori',\n",
       "  'cellular',\n",
       "  'partit',\n",
       "  'standard',\n",
       "  'boundari'],\n",
       " 4: ['object',\n",
       "  'two',\n",
       "  'approxim',\n",
       "  'flow',\n",
       "  'systems',\n",
       "  'color',\n",
       "  'asymptot',\n",
       "  'augment',\n",
       "  'move',\n",
       "  'altern'],\n",
       " 5: ['environ',\n",
       "  'constraint',\n",
       "  'cooper',\n",
       "  'fade',\n",
       "  'complet',\n",
       "  'presenc',\n",
       "  'consist',\n",
       "  'urban',\n",
       "  'transact',\n",
       "  'multius'],\n",
       " 6: ['parallel',\n",
       "  'databas',\n",
       "  'state',\n",
       "  'motion',\n",
       "  'larg',\n",
       "  'fault',\n",
       "  'block',\n",
       "  'depend',\n",
       "  'numer',\n",
       "  'spars'],\n",
       " 7: ['featur',\n",
       "  'type',\n",
       "  'condit',\n",
       "  'evolut',\n",
       "  'train',\n",
       "  'respons',\n",
       "  'mode',\n",
       "  'dual',\n",
       "  'higher',\n",
       "  'strong'],\n",
       " 8: ['domain',\n",
       "  'order',\n",
       "  'partial',\n",
       "  'ontolog',\n",
       "  'workshop',\n",
       "  'specif',\n",
       "  'investig',\n",
       "  'broadcast',\n",
       "  'modular',\n",
       "  'encod'],\n",
       " 9: ['process',\n",
       "  'differenti',\n",
       "  'monitor',\n",
       "  'content',\n",
       "  'busi',\n",
       "  'dure',\n",
       "  'output',\n",
       "  'record',\n",
       "  'interconnect',\n",
       "  'achiev'],\n",
       " 10: ['simul',\n",
       "  'secur',\n",
       "  'game',\n",
       "  'sens',\n",
       "  'joint',\n",
       "  'polici',\n",
       "  'reduc',\n",
       "  'brain',\n",
       "  'vision',\n",
       "  'size'],\n",
       " 11: ['model',\n",
       "  'cost',\n",
       "  'bayesian',\n",
       "  'formal',\n",
       "  'markov',\n",
       "  'check',\n",
       "  'queue',\n",
       "  'generic',\n",
       "  'hidden',\n",
       "  'parametr'],\n",
       " 12: ['implement',\n",
       "  'set',\n",
       "  'novel',\n",
       "  'combin',\n",
       "  'spatial',\n",
       "  'point',\n",
       "  'path',\n",
       "  'global',\n",
       "  'direct',\n",
       "  'factor'],\n",
       " 13: ['method',\n",
       "  'access',\n",
       "  'collabor',\n",
       "  'energi',\n",
       "  'discret',\n",
       "  'platform',\n",
       "  'matrix',\n",
       "  'algebra',\n",
       "  'array',\n",
       "  'classifi'],\n",
       " 14: ['inform',\n",
       "  'technolog',\n",
       "  'retriev',\n",
       "  'extract',\n",
       "  'trust',\n",
       "  'converg',\n",
       "  'annot',\n",
       "  'transport',\n",
       "  'planar',\n",
       "  'bodi'],\n",
       " 15: ['schedul',\n",
       "  'random',\n",
       "  'identif',\n",
       "  'und',\n",
       "  'der',\n",
       "  'peer',\n",
       "  'von',\n",
       "  'quantit',\n",
       "  'analys',\n",
       "  'zur'],\n",
       " 16: ['generat',\n",
       "  'user',\n",
       "  'intern',\n",
       "  'probabilist',\n",
       "  'perspect',\n",
       "  'mesh',\n",
       "  'des',\n",
       "  'interpret',\n",
       "  'pair',\n",
       "  'coeffici'],\n",
       " 17: ['use',\n",
       "  'estim',\n",
       "  'predict',\n",
       "  'plan',\n",
       "  'compar',\n",
       "  'compon',\n",
       "  'enterpris',\n",
       "  'execut',\n",
       "  'failur',\n",
       "  'workflow'],\n",
       " 18: ['base',\n",
       "  'test',\n",
       "  'experi',\n",
       "  'class',\n",
       "  'review',\n",
       "  'methodolog',\n",
       "  'requir',\n",
       "  'decomposit',\n",
       "  'natur',\n",
       "  'probabl'],\n",
       " 19: ['imag',\n",
       "  'measur',\n",
       "  'multipl',\n",
       "  'video',\n",
       "  'segment',\n",
       "  'context',\n",
       "  'rate',\n",
       "  'internet',\n",
       "  'correl',\n",
       "  'switch'],\n",
       " 20: ['design',\n",
       "  'dynam',\n",
       "  'perform',\n",
       "  'high',\n",
       "  'filter',\n",
       "  'construct',\n",
       "  'represent',\n",
       "  'interfac',\n",
       "  'scale',\n",
       "  'scalabl'],\n",
       " 21: ['applic',\n",
       "  'detect',\n",
       "  'fuzzi',\n",
       "  'speech',\n",
       "  'signal',\n",
       "  'properti',\n",
       "  'special',\n",
       "  'processor',\n",
       "  'rank',\n",
       "  'separ'],\n",
       " 22: ['mobil',\n",
       "  'robot',\n",
       "  'space',\n",
       "  'intellig',\n",
       "  'agent',\n",
       "  'artifici',\n",
       "  'face',\n",
       "  'smart',\n",
       "  'manipul',\n",
       "  'authent'],\n",
       " 23: ['architectur',\n",
       "  'languag',\n",
       "  'sourc',\n",
       "  'spectrum',\n",
       "  'descript',\n",
       "  'align',\n",
       "  'blind',\n",
       "  'famili',\n",
       "  'sensit',\n",
       "  'simultan'],\n",
       " 24: ['framework',\n",
       "  'general',\n",
       "  'transform',\n",
       "  'sequenc',\n",
       "  'paramet',\n",
       "  'tempor',\n",
       "  'particl',\n",
       "  'spectral',\n",
       "  'correct',\n",
       "  'work'],\n",
       " 25: ['comput',\n",
       "  'power',\n",
       "  'bound',\n",
       "  'cloud',\n",
       "  'compress',\n",
       "  'sampl',\n",
       "  'topolog',\n",
       "  'input',\n",
       "  'hardwar',\n",
       "  'electr'],\n",
       " 26: ['improv',\n",
       "  'real',\n",
       "  'visual',\n",
       "  'map',\n",
       "  'qualiti',\n",
       "  'synchron',\n",
       "  'phase',\n",
       "  'analyz',\n",
       "  'principl',\n",
       "  'scientif'],\n",
       " 27: ['web',\n",
       "  'onlin',\n",
       "  'level',\n",
       "  'interfer',\n",
       "  'univers',\n",
       "  'analyt',\n",
       "  'orient',\n",
       "  'price',\n",
       "  'cach',\n",
       "  'invari'],\n",
       " 28: ['optim',\n",
       "  'rout',\n",
       "  'oper',\n",
       "  'queri',\n",
       "  'appli',\n",
       "  'nois',\n",
       "  'abstract',\n",
       "  'fusion',\n",
       "  'swarm',\n",
       "  'identifi'],\n",
       " 29: ['network',\n",
       "  'wireless',\n",
       "  'sensor',\n",
       "  'softwar',\n",
       "  'neural',\n",
       "  'express',\n",
       "  'composit',\n",
       "  'posit',\n",
       "  'infer',\n",
       "  'gene'],\n",
       " 30: ['semant',\n",
       "  'circuit',\n",
       "  'variabl',\n",
       "  'extend',\n",
       "  'layer',\n",
       "  'deriv',\n",
       "  'computer',\n",
       "  'choic',\n",
       "  'precis',\n",
       "  'question'],\n",
       " 31: ['local',\n",
       "  'logic',\n",
       "  'delay',\n",
       "  'explor',\n",
       "  'person',\n",
       "  'reason',\n",
       "  'area',\n",
       "  'determin',\n",
       "  'node',\n",
       "  'calcul'],\n",
       " 32: ['multi',\n",
       "  'program',\n",
       "  'techniqu',\n",
       "  'self',\n",
       "  'statist',\n",
       "  'key',\n",
       "  'mean',\n",
       "  'reconfigur',\n",
       "  'environment',\n",
       "  'optimis'],\n",
       " 33: ['channel',\n",
       "  'protocol',\n",
       "  'weight',\n",
       "  'transmiss',\n",
       "  'attack',\n",
       "  'coordin',\n",
       "  'introduct',\n",
       "  'quantum',\n",
       "  'navig',\n",
       "  'independ'],\n",
       " 34: ['integr',\n",
       "  'low',\n",
       "  'field',\n",
       "  'embed',\n",
       "  'devic',\n",
       "  'modul',\n",
       "  'link',\n",
       "  'concept',\n",
       "  'part',\n",
       "  'theorem'],\n",
       " 35: ['control',\n",
       "  'match',\n",
       "  'surfac',\n",
       "  'reconstruct',\n",
       "  'flexibl',\n",
       "  'curv',\n",
       "  'concurr',\n",
       "  'convex',\n",
       "  'exact',\n",
       "  'loop'],\n",
       " 36: ['servic',\n",
       "  'search',\n",
       "  'decis',\n",
       "  'hierarch',\n",
       "  'confer',\n",
       "  'index',\n",
       "  'similar',\n",
       "  'view',\n",
       "  'util',\n",
       "  'messag'],\n",
       " 37: ['analysi',\n",
       "  'learn',\n",
       "  'function',\n",
       "  'traffic',\n",
       "  'task',\n",
       "  'iter',\n",
       "  'region',\n",
       "  'distanc',\n",
       "  'observ',\n",
       "  'balanc'],\n",
       " 38: ['equat',\n",
       "  'assess',\n",
       "  'impact',\n",
       "  'reduct',\n",
       "  'synthesi',\n",
       "  'polynomi',\n",
       "  'scienc',\n",
       "  'variat',\n",
       "  'gaussian',\n",
       "  'geometr'],\n",
       " 39: ['algorithm',\n",
       "  'approach',\n",
       "  'knowledg',\n",
       "  'machin',\n",
       "  'fast',\n",
       "  'tool',\n",
       "  'genet',\n",
       "  'grid',\n",
       "  'connect',\n",
       "  'maximum'],\n",
       " 40: ['studi',\n",
       "  'recognit',\n",
       "  'cluster',\n",
       "  'classif',\n",
       "  'social',\n",
       "  'via',\n",
       "  'mechan',\n",
       "  'rule',\n",
       "  'feedback',\n",
       "  'optic'],\n",
       " 41: ['relat',\n",
       "  'alloc',\n",
       "  'cognit',\n",
       "  'capac',\n",
       "  'extens',\n",
       "  'paper',\n",
       "  'qos',\n",
       "  'multicast',\n",
       "  'awar',\n",
       "  'lattic'],\n",
       " 42: ['hybrid',\n",
       "  'track',\n",
       "  'comparison',\n",
       "  'vector',\n",
       "  'reliabl',\n",
       "  'three',\n",
       "  'evolutionari',\n",
       "  'ieee',\n",
       "  'first',\n",
       "  'uncertainti'],\n",
       " 43: ['system',\n",
       "  'evalu',\n",
       "  'autom',\n",
       "  'open',\n",
       "  'vehicl',\n",
       "  'note',\n",
       "  'mix',\n",
       "  'recommend',\n",
       "  'diagnosi',\n",
       "  'within'],\n",
       " 44: ['problem',\n",
       "  'effici',\n",
       "  'graph',\n",
       "  'scheme',\n",
       "  'toward',\n",
       "  'human',\n",
       "  'pattern',\n",
       "  'tree',\n",
       "  'behavior',\n",
       "  'solv'],\n",
       " 45: ['code',\n",
       "  'communic',\n",
       "  'error',\n",
       "  'issu',\n",
       "  'cross',\n",
       "  'decod',\n",
       "  'load',\n",
       "  'privaci',\n",
       "  'ofdm',\n",
       "  'camera'],\n",
       " 46: ['manag',\n",
       "  'solut',\n",
       "  'document',\n",
       "  'continu',\n",
       "  'chain',\n",
       "  'experiment',\n",
       "  'suppli',\n",
       "  'storag',\n",
       "  'unit',\n",
       "  'xml'],\n",
       " 47: ['new',\n",
       "  'effect',\n",
       "  'interact',\n",
       "  'select',\n",
       "  'case',\n",
       "  'digit',\n",
       "  'research',\n",
       "  'virtual',\n",
       "  'theori',\n",
       "  'activ'],\n",
       " 48: ['engin',\n",
       "  'differ',\n",
       "  'mimo',\n",
       "  'frequenc',\n",
       "  'cell',\n",
       "  'word',\n",
       "  'characterist',\n",
       "  'transfer',\n",
       "  'sequenti',\n",
       "  'propag'],\n",
       " 49: ['adapt',\n",
       "  'support',\n",
       "  'group',\n",
       "  'heterogen',\n",
       "  'multimedia',\n",
       "  'associ',\n",
       "  'challeng',\n",
       "  'autonom',\n",
       "  'make',\n",
       "  'without']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the number of components from 10 to 50, what we do is simply adding topics to the model. And we are getting more topics with different words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Now apply PCA to the same dataset with different number of principle components 10, 20, 50. Also print out top 10 words for each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topwords_pca(cv, pca, num_topwords):\n",
    "    \"\"\"\n",
    "    print the top words based on the eigenvectors \n",
    "    \"\"\"\n",
    "    Topwords = []\n",
    "    vocab = {v: k for k, v in cv.vocabulary_.items()}\n",
    "    eigenvectors = pca.components_\n",
    "    for k,ev in enumerate(eigenvectors):\n",
    "        ev_indices = np.argsort(- np.abs(ev))[:num_topwords]\n",
    "        ev_topwords =', '.join([vocab[ind] for ind in ev_indices])\n",
    "        Topwords.append(ev_topwords)\n",
    "        print(\"Component : %d, topwords : %s\" % (k, ev_topwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svd(num_comp, data, matrix):\n",
    "    svd = TruncatedSVD(n_components = num_comp)\n",
    "    svd.fit(matrix)\n",
    "    return topwords_pca(data, svd, num_topwords=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component : 0, topwords : system, use, model, network, base, algorithm, analysi, data, design, control\n",
      "Component : 1, topwords : system, network, use, model, algorithm, wireless, neural, sensor, data, imag\n",
      "Component : 2, topwords : network, model, use, wireless, system, sensor, neural, imag, mobil, ad\n",
      "Component : 3, topwords : model, use, network, base, imag, system, algorithm, detect, wireless, applic\n",
      "Component : 4, topwords : base, algorithm, network, use, model, system, data, analysi, imag, optim\n",
      "Component : 5, topwords : algorithm, base, problem, optim, data, model, comput, genet, analysi, parallel\n",
      "Component : 6, topwords : data, analysi, base, applic, algorithm, use, comput, approach, perform, design\n",
      "Component : 7, topwords : analysi, data, design, perform, control, comput, algorithm, system, mine, manag\n",
      "Component : 8, topwords : design, analysi, comput, approach, applic, algorithm, data, control, system, base\n",
      "Component : 9, topwords : comput, design, control, approach, data, imag, optim, applic, process, method\n"
     ]
    }
   ],
   "source": [
    "run_svd(10, X, X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component : 0, topwords : system, use, model, network, base, algorithm, analysi, data, design, control\n",
      "Component : 1, topwords : system, network, use, model, algorithm, wireless, neural, sensor, data, imag\n",
      "Component : 2, topwords : network, model, use, wireless, system, sensor, neural, imag, mobil, ad\n",
      "Component : 3, topwords : model, use, network, base, imag, system, algorithm, detect, wireless, applic\n",
      "Component : 4, topwords : base, algorithm, network, use, model, system, data, analysi, method, optim\n",
      "Component : 5, topwords : algorithm, base, problem, optim, data, model, comput, genet, analysi, parallel\n",
      "Component : 6, topwords : data, analysi, base, applic, algorithm, use, comput, design, approach, model\n",
      "Component : 7, topwords : analysi, data, design, algorithm, perform, control, system, applic, mine, comput\n",
      "Component : 8, topwords : design, analysi, comput, applic, approach, algorithm, control, system, data, base\n",
      "Component : 9, topwords : comput, design, control, data, applic, imag, method, algorithm, optim, distribut\n",
      "Component : 10, topwords : approach, design, control, comput, optim, base, data, problem, imag, algorithm\n",
      "Component : 11, topwords : control, approach, inform, optim, comput, imag, method, data, algorithm, design\n",
      "Component : 12, topwords : applic, approach, imag, comput, method, design, control, analysi, inform, base\n",
      "Component : 13, topwords : method, imag, applic, optim, web, control, inform, problem, design, servic\n",
      "Component : 14, topwords : imag, method, optim, control, inform, problem, comput, design, approach, web\n",
      "Component : 15, topwords : inform, applic, control, approach, imag, web, process, servic, learn, manag\n",
      "Component : 16, topwords : optim, method, multi, imag, algorithm, control, learn, process, approach, inform\n",
      "Component : 17, topwords : inform, learn, servic, applic, web, distribut, perform, program, process, multi\n",
      "Component : 18, topwords : multi, learn, process, distribut, dynam, servic, web, inform, time, perform\n",
      "Component : 19, topwords : learn, multi, process, problem, web, servic, method, program, distribut, adapt\n"
     ]
    }
   ],
   "source": [
    "run_svd(20, X, X_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component : 0, topwords : system, use, model, network, base, algorithm, analysi, data, design, control\n",
      "Component : 1, topwords : system, network, use, model, algorithm, wireless, neural, sensor, data, imag\n",
      "Component : 2, topwords : network, model, use, wireless, system, sensor, neural, imag, mobil, ad\n",
      "Component : 3, topwords : model, use, network, base, imag, system, algorithm, detect, wireless, applic\n",
      "Component : 4, topwords : base, algorithm, network, use, model, system, data, analysi, method, optim\n",
      "Component : 5, topwords : algorithm, base, problem, optim, data, model, comput, genet, analysi, parallel\n",
      "Component : 6, topwords : data, analysi, base, applic, algorithm, use, comput, design, approach, model\n",
      "Component : 7, topwords : analysi, data, design, perform, algorithm, control, system, mine, applic, comput\n",
      "Component : 8, topwords : design, analysi, comput, applic, approach, algorithm, control, system, data, base\n",
      "Component : 9, topwords : comput, design, control, data, applic, imag, algorithm, method, optim, distribut\n",
      "Component : 10, topwords : approach, design, control, comput, optim, base, problem, imag, data, applic\n",
      "Component : 11, topwords : control, approach, inform, optim, comput, imag, method, design, algorithm, data\n",
      "Component : 12, topwords : applic, approach, imag, comput, method, control, inform, web, analysi, design\n",
      "Component : 13, topwords : method, imag, applic, optim, web, inform, control, servic, design, base\n",
      "Component : 14, topwords : imag, method, optim, control, inform, problem, comput, approach, web, design\n",
      "Component : 15, topwords : inform, applic, control, imag, approach, process, web, optim, servic, manag\n",
      "Component : 16, topwords : optim, method, multi, imag, algorithm, control, approach, inform, new, learn\n",
      "Component : 17, topwords : inform, multi, distribut, learn, applic, servic, process, web, softwar, environ\n",
      "Component : 18, topwords : learn, distribut, multi, process, problem, softwar, perform, manag, approach, method\n",
      "Component : 19, topwords : multi, learn, optim, inform, distribut, process, web, wireless, neural, servic\n",
      "Component : 20, topwords : web, process, servic, problem, learn, distribut, program, method, optim, softwar\n",
      "Component : 21, topwords : distribut, process, problem, softwar, multi, learn, studi, perform, program, inform\n",
      "Component : 22, topwords : problem, learn, distribut, optim, web, servic, program, method, perform, imag\n",
      "Component : 23, topwords : perform, process, evalu, distribut, program, dynam, code, studi, multi, high\n",
      "Component : 24, topwords : dynam, program, problem, perform, logic, studi, learn, mobil, evalu, parallel\n",
      "Component : 25, topwords : time, studi, process, program, softwar, adapt, case, detect, dynam, manag\n",
      "Component : 26, topwords : dynam, mobil, web, manag, program, perform, studi, logic, evalu, process\n",
      "Component : 27, topwords : studi, time, mobil, program, dynam, case, wireless, neural, effici, sensor\n",
      "Component : 28, topwords : perform, dynam, time, studi, code, detect, softwar, evalu, effici, wireless\n",
      "Component : 29, topwords : time, manag, studi, detect, softwar, process, case, dynam, web, wireless\n",
      "Component : 30, topwords : softwar, mobil, time, detect, studi, code, program, manag, adapt, process\n",
      "Component : 31, topwords : detect, code, effici, mobil, object, adapt, evalu, time, scheme, wireless\n",
      "Component : 32, topwords : manag, softwar, develop, detect, mobil, effici, studi, knowledg, wireless, engin\n",
      "Component : 33, topwords : adapt, effici, graph, code, wireless, program, sensor, mobil, simul, control\n",
      "Component : 34, topwords : wireless, sensor, mobil, code, graph, adapt, neural, time, new, program\n",
      "Component : 35, topwords : graph, code, adapt, effici, function, structur, evalu, fuzzi, integr, dynam\n",
      "Component : 36, topwords : effici, graph, new, wireless, sensor, adapt, parallel, function, neural, support\n",
      "Component : 37, topwords : new, graph, code, effici, function, parallel, simul, method, scheme, approach\n",
      "Component : 38, topwords : estim, parallel, simul, structur, graph, integr, function, new, detect, recognit\n",
      "Component : 39, topwords : simul, servic, integr, estim, graph, high, web, environ, architectur, code\n",
      "Component : 40, topwords : integr, evalu, architectur, servic, web, high, support, structur, estim, function\n",
      "Component : 41, topwords : estim, integr, simul, evalu, parallel, code, architectur, new, channel, web\n",
      "Component : 42, topwords : structur, evalu, estim, fuzzi, parallel, support, environ, architectur, perform, high\n",
      "Component : 43, topwords : object, simul, function, structur, servic, recognit, fuzzi, web, support, integr\n",
      "Component : 44, topwords : evalu, architectur, high, parallel, object, test, integr, generat, support, perform\n",
      "Component : 45, topwords : function, servic, environ, web, parallel, structur, mobil, generat, object, new\n",
      "Component : 46, topwords : support, environ, simul, object, servic, recognit, parallel, evalu, test, virtual\n",
      "Component : 47, topwords : integr, improv, environ, estim, object, parallel, support, framework, recognit, test\n",
      "Component : 48, topwords : fuzzi, function, logic, support, environ, set, high, program, interact, search\n",
      "Component : 49, topwords : architectur, support, environ, interact, fuzzi, secur, object, machin, logic, develop\n"
     ]
    }
   ],
   "source": [
    "run_svd(50, X, X_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the number of components, the result of pca seems better because there are more topics appearing rather than using different combinations of a group of indentical words to form topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, I think LDA is much better than PCA because there lots of words that occur in many topics. This result is really confusing as it cannot clearly identify different topic which also makes furthre analysis harder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
